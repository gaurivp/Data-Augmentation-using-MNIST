Firstly, this project was implemented on Google Colab platform as it enables the user to connect to the GPU. Libraries such as NumPy, Matplotlib, Tensorflow, Keras and dataset are imported. The main aim of this project was to import libraries and dataset, apply data augmentation, generate a new dataset, execute a convolution neural network, and obtain the desired results. The problem to be solved is decreased accuracy, problem of overfitting and limited amount of ground truth data. Data augmentation is a technique of generation of new training samples by applying various a list of transformations. The transformations might include random shifts, cropping, erasing, addition of noise, random flips, zooming and many more. 


ZCA whitening is a process where the data displays decorrelated features. This parameter was set to a boolean value of “True”. The horizontal and vertical flip were set to “True” which indicated that the pixels of rows and columns were reversed. Further, the rotation angle was set to a value of 45. This shows that every image of handwritten digit was rotated at an angle of 45 degrees. Rotation is a parameter which takes the input ranging from 0 to 360 degrees. Floating point numbers can be seen in the shift parameters which implies that the images undergo a horizontal and vertical shiftby 50%. The zoom and brightness parametersare specified in floating point ranges. Here, the zoom parameters were specified as [0.5,1.0]. The zoom operation enables the pixel zooming in a uniform manner throughout the image. The brightness range for this project was set to [0.2,1.0]. The aim of specifying the brightness parameter is to enable the model to be accustomed to a dataset which contains images of different brightness levels.


The above data augmentation parameters were further applied to a CNN network. The CNN network consisted of three convolutional layers of 64, 32 and 32 neurons respectively with ReLU activation function. The kernel size was set to 5. The output layer of the convolutional neural network consisted of 10 units with softmax activation function. The above model was compiled with the Adam optimizer and categorial cross entropy loss function. The number of epochs and batch size were set to 100 and 128 respectively. After the successful execution of the above specified model, the accuracies are determined. 


The total time taken for the execution of model was approximately 900 seconds which amounts to approximately 15 minutes. Using data augmentation, model accuracy was increased to around 99%. Also, this proved to be a cost-effective solution. In addition to this, the problem of overfitting was solved.
